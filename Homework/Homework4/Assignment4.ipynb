{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96bafbc1",
   "metadata": {},
   "source": [
    "### Assignment 4. Mental Health Disorder Classification \n",
    "\n",
    "This assignment is to develop a decision tree model (random forests) to predict mental health disorder classification from a collection of symptoms.  The objective of this study is to determine whether we can develop quantitative analysis that predicts mental health diagnosis, and useful results that can inform practice (without doing all this analysis)\n",
    " \n",
    "This data set is mostly categorical variables, e.g., mood swings (yes/no).  For categorical decision trees can make more intuitive sense since the boundaries separate the different categories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182d5dea",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-02-10T13:23:53.358526Z",
     "iopub.status.busy": "2024-02-10T13:23:53.358006Z",
     "iopub.status.idle": "2024-02-10T13:23:55.766852Z",
     "shell.execute_reply": "2024-02-10T13:23:55.765386Z"
    },
    "papermill": {
     "duration": 2.423632,
     "end_time": "2024-02-10T13:23:55.769876",
     "exception": false,
     "start_time": "2024-02-10T13:23:53.346244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV  # this is a new method\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2c03bc",
   "metadata": {
    "papermill": {
     "duration": 0.00853,
     "end_time": "2024-02-10T13:23:55.787514",
     "exception": false,
     "start_time": "2024-02-10T13:23:55.778984",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8f51e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-10T13:23:55.808083Z",
     "iopub.status.busy": "2024-02-10T13:23:55.806772Z",
     "iopub.status.idle": "2024-02-10T13:23:55.852816Z",
     "shell.execute_reply": "2024-02-10T13:23:55.851627Z"
    },
    "papermill": {
     "duration": 0.059582,
     "end_time": "2024-02-10T13:23:55.855858",
     "exception": false,
     "start_time": "2024-02-10T13:23:55.796276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleaned_mental_disorder_data.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a723caa8",
   "metadata": {},
   "source": [
    "Every single variable in this data set is categorical!  Lets take a quick look "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd2fa35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-10T13:23:55.896118Z",
     "iopub.status.busy": "2024-02-10T13:23:55.894805Z",
     "iopub.status.idle": "2024-02-10T13:23:55.918691Z",
     "shell.execute_reply": "2024-02-10T13:23:55.917613Z"
    },
    "papermill": {
     "duration": 0.037261,
     "end_time": "2024-02-10T13:23:55.921150",
     "exception": false,
     "start_time": "2024-02-10T13:23:55.883889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# display the first few rows\n",
    "print(\"First few rows of the dataset:\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb5e743",
   "metadata": {},
   "source": [
    "Use the scroll bar to look at all the variables.  \n",
    "We can see that everything has been encoded as text strings, even potentially numeric variables like Sexual Acitivity, Concentration, and Optimism.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58959c21",
   "metadata": {},
   "source": [
    "Because I obsess about these things, I am going to fix the misspelling on two column headers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fd4894",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'Anorxia': 'Anorexia', 'Expert Diagnose':'Expert Diagnosis', 'Sleep dissorder':'Sleep disorder'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d917260a",
   "metadata": {},
   "source": [
    "1. Are there any missing values in the data set?  If there are remove those observations from the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c8db7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-10T13:23:55.942236Z",
     "iopub.status.busy": "2024-02-10T13:23:55.941779Z",
     "iopub.status.idle": "2024-02-10T13:23:55.959630Z",
     "shell.execute_reply": "2024-02-10T13:23:55.958506Z"
    },
    "papermill": {
     "duration": 0.031454,
     "end_time": "2024-02-10T13:23:55.962133",
     "exception": false,
     "start_time": "2024-02-10T13:23:55.930679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d88b5e66",
   "metadata": {},
   "source": [
    "Because this is categorical data, it will be useful to understand what are the possible values of each variable.  We can use the unique method to find this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0641492d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-10T13:23:55.983991Z",
     "iopub.status.busy": "2024-02-10T13:23:55.983246Z",
     "iopub.status.idle": "2024-02-10T13:23:55.997749Z",
     "shell.execute_reply": "2024-02-10T13:23:55.996493Z"
    },
    "papermill": {
     "duration": 0.028823,
     "end_time": "2024-02-10T13:23:56.000636",
     "exception": false,
     "start_time": "2024-02-10T13:23:55.971813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check for unique value\n",
    "for column in df.columns:\n",
    "    unique_values = df[column].unique()\n",
    "    print(f\"\\nUnique values in '{column}':\\n{unique_values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0dfb13",
   "metadata": {
    "papermill": {
     "duration": 0.009636,
     "end_time": "2024-02-10T13:23:56.074769",
     "exception": false,
     "start_time": "2024-02-10T13:23:56.065133",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- There is of course a brute force approach to encoding this data numerically that could work, but thats throwing out the baby with the bath water. \n",
    "\n",
    "- There are 4 types of variables. \n",
    "    - 'Expert Diagnosis' has 4 categorical variables that bear no particular relationship.  Since this is the target variable for classification, we can actually leave them as is and it will facilitate making most of the tables and plots. DO NOT ENCODE!\n",
    "    - 7 variables have 'YES' and 'NO' as the two possibilities.  It would be ideal to encode 'YES' as 1 and 'NO' as 0 \n",
    "    - 3 variables are encoded as '3 from 10', etc.  This indicates that on a scale of 10 a numeric score of 3 was given.  These should be ideally converted to numeric values \n",
    "    - 4 variables have descriptive values, [Seldom' 'Sometimes' 'Usually' ''Most-Often'].   These are actually ordered values, wwith 'Seldom' as the least, and 'Most-Often' as the most.They should be numerically encoded to reflect their relative strength. \n",
    "\n",
    "Since we desire to make a careful encoding, using pd.get_dummies will not work that well.  We should instead be specific about the encoding.  Here is an example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012e9c2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-10T13:23:56.096733Z",
     "iopub.status.busy": "2024-02-10T13:23:56.096305Z",
     "iopub.status.idle": "2024-02-10T13:23:56.163817Z",
     "shell.execute_reply": "2024-02-10T13:23:56.162420Z"
    },
    "papermill": {
     "duration": 0.081669,
     "end_time": "2024-02-10T13:23:56.166416",
     "exception": false,
     "start_time": "2024-02-10T13:23:56.084747",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# desired encoding categorical variables\n",
    "\n",
    "encoder = {'Seldom':1, 'Sometimes':2, 'Usually':3, 'Most-Often':4}\n",
    "for j in df.columns[0:4]:\n",
    "    df[j] = df[j].map(encoder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fde3ad7",
   "metadata": {},
   "source": [
    "2. Using similar logic, encode the other predictor variables as numeric quantities.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8767295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "543ad30e",
   "metadata": {
    "papermill": {
     "duration": 0.010237,
     "end_time": "2024-02-10T13:23:56.187210",
     "exception": false,
     "start_time": "2024-02-10T13:23:56.176973",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Exploratory Data Analysis - You need to do this to understand your results! \n",
    "Since these are all categorical variables, it makes the most sense to use histograms or count plots.  There are a lot of plots to look at.  When you do that, its very useful to come up with a systematic way to label things using colors to help your reader. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5a1b75",
   "metadata": {},
   "source": [
    "3. Make a plot using sns.countplot that shows the number of patients with each diagnosis.  when you make this plot, choose the `palette` argument carefully, because this will assign each of the diagnosis a different color.  We want to keep that consistent throughout the notebook.  I  control this by setting `hue` = 'Expert Diagnosis' and `palette` = 'bright' but there are other popular palettes.  You can suppress the legend using `legend` = False.  Also take control of the order in which the different diagnosis are presented so they make sense, by provding the `order` as a list of the diagnoses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd9eef3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6249b33",
   "metadata": {},
   "source": [
    "Now, plot all the predictors variables as histograms. My call inside a loop lindexed by i ooked like this - \n",
    "\n",
    "`sns.histplot(data=df, x=df.columns[i], hue='Expert Diagnosis', hue_order = ['Depression','Bipolar Type-1','Bipolar Type-2','Normal'],multiple=\"dodge\", kde=True, palette=\"bright\",legend=False)`\n",
    "\n",
    "You dont need a legend here, because the previous plot assigned a color to each diagnosis and I am following the same color scheme here.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cad830",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-10T13:23:56.210273Z",
     "iopub.status.busy": "2024-02-10T13:23:56.209830Z",
     "iopub.status.idle": "2024-02-10T13:24:05.108256Z",
     "shell.execute_reply": "2024-02-10T13:24:05.106779Z"
    },
    "papermill": {
     "duration": 8.914137,
     "end_time": "2024-02-10T13:24:05.111782",
     "exception": false,
     "start_time": "2024-02-10T13:23:56.197645",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43b9912d",
   "metadata": {},
   "source": [
    "4.  Split the data into test and training sets. I put 30% into my test set.  Separate the target 'Expert Diagnosis' as the y variable and all the predictors as X.  \n",
    "- **Its very important to stratify correctly.**  That is, we want the test data to be balanced in the same way as the training data.  \n",
    "- If you called the target variable y, then include a parameter `stratify = y` when you split the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7561f659",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-10T13:24:06.360997Z",
     "iopub.status.busy": "2024-02-10T13:24:06.360511Z",
     "iopub.status.idle": "2024-02-10T13:24:06.491447Z",
     "shell.execute_reply": "2024-02-10T13:24:06.490254Z"
    },
    "papermill": {
     "duration": 0.153236,
     "end_time": "2024-02-10T13:24:06.494384",
     "exception": false,
     "start_time": "2024-02-10T13:24:06.341148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94eb9e47",
   "metadata": {
    "papermill": {
     "duration": 0.016932,
     "end_time": "2024-02-10T13:24:07.079867",
     "exception": false,
     "start_time": "2024-02-10T13:24:07.062935",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "5. Set up a random forest classifiers.  We need to use GridSearchCV to optimize two hyperparameters - `n_estimators`, the number of trees and max_depth.  I used n_estimators ranging from 100 to 400 and max_depth ranging from 1 to 5.  For scoring lets use accuracy.  I usually do 5-fold cross validation by default. Fit the classifier to the training data. \n",
    "\n",
    "Report \n",
    "    - best max-depth\n",
    "    - best n_estimators\n",
    "    - best Accuracy \n",
    "\n",
    "Extract the best rf model from your fit.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969200b7",
   "metadata": {
    "_kg_hide-output": false,
    "execution": {
     "iopub.execute_input": "2024-02-10T13:24:07.117995Z",
     "iopub.status.busy": "2024-02-10T13:24:07.116559Z",
     "iopub.status.idle": "2024-02-10T13:24:34.232424Z",
     "shell.execute_reply": "2024-02-10T13:24:34.230898Z"
    },
    "papermill": {
     "duration": 27.138523,
     "end_time": "2024-02-10T13:24:34.235271",
     "exception": false,
     "start_time": "2024-02-10T13:24:07.096748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b86cf8",
   "metadata": {
    "papermill": {
     "duration": 0.019218,
     "end_time": "2024-02-10T13:24:35.164937",
     "exception": false,
     "start_time": "2024-02-10T13:24:35.145719",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "6. Evaluate your classifier by predicting the test data.\n",
    "\n",
    "Present \n",
    "\n",
    "- the accuracy score \n",
    "- classification report.  \n",
    "\n",
    "In the markdown below, write down what the precision and recall values are telling you about hen this model performs well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e41c98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-10T13:24:35.206720Z",
     "iopub.status.busy": "2024-02-10T13:24:35.205500Z",
     "iopub.status.idle": "2024-02-10T13:24:35.232958Z",
     "shell.execute_reply": "2024-02-10T13:24:35.231323Z"
    },
    "papermill": {
     "duration": 0.0514,
     "end_time": "2024-02-10T13:24:35.235673",
     "exception": false,
     "start_time": "2024-02-10T13:24:35.184273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0385aecd",
   "metadata": {},
   "source": [
    "Comment on accuracy, precision, and recall. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed01b72",
   "metadata": {
    "papermill": {
     "duration": 0.021133,
     "end_time": "2024-02-10T13:24:36.167923",
     "exception": false,
     "start_time": "2024-02-10T13:24:36.146790",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "7. Make a confusion matrix to look at the pattern of misclassification.  When you do this, you will see that it labels the diagnoses as 0,1,2,3.  This is because internally, random forest mapped the conditions onto numeric values.  To find the mapping, look at `.classes_' of your best random forest object. In my case, it looked like this. \n",
    "\n",
    "['Bipolar Type-1' 'Bipolar Type-2' 'Depression' 'Normal']\n",
    "\n",
    "so thats the order of conditions, and you should be able to fix your labels. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a394381f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cf7713",
   "metadata": {},
   "source": [
    "8. To evaluate which predictors were useful for the classifier, use permutation_importance rather than partial dependence.  When we have more than 2 classes, permutation_important becomes harder to interpret as the model considers classifying one versus the rest.  Permutation importance tells us how much accuracy will decline if randomize the variable.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0435ce47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d7af52e",
   "metadata": {},
   "source": [
    "Write 1-2 paragraphs that summarizes\n",
    "\n",
    "1.  what is the data and what is the question being asked of the data. \n",
    "2. what the model you made was, and how well the model performed.  What kind of errors if any does it make.  \n",
    "3. What features of the data were most informative of mental health diagnosis.  \n",
    "4. Can you provide a simple explanation of how to make a preliminary diagnosis that could be provided to counselors and first responders? \n",
    "5. If you had limited space and could only show a few of these figures, which ones would you show? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cba262",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4352146,
     "sourceId": 7476679,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30646,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 48.798007,
   "end_time": "2024-02-10T13:24:38.811185",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-02-10T13:23:50.013178",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
